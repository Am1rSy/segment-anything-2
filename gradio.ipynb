{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/sam/transformer.py:22: UserWarning: Flash Attention is disabled as it requires a GPU with Ampere (8.0) CUDA capability.\n",
      "  OLD_GPU, USE_FLASH_ATTN, MATH_KERNEL_ON = get_sdpa_settings()\n",
      "/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/layouts/column.py:55: UserWarning: 'scale' value should be an integer. Using 0.5 will cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://1143c8974ed3d652dc.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1143c8974ed3d652dc.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get meta information of input video\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-11)\n",
      "  configuration: --prefix=/home/conda/feedstock_root/build_artifacts/ffmpeg_1718892157037/_h_env_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_placehold_plac --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1718892157037/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1718892157037/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1718892157037/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1718892157037/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1718892157037/_build_env/bin/pkg-config\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "-vsync is deprecated. Use -fps_mode\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/var/tmp/pbs.9988502.pbs/gradio/48cfa87972079e02c195764ddd54e87b68ba08d87be69f481dc4b465636a8236/A1-8_5s.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp41isom\n",
      "    creation_time   : 2024-07-15T10:27:38.000000Z\n",
      "  Duration: 00:00:06.53, start: 0.000000, bitrate: 18130 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p(tv, progressive), 1392x1040 [SAR 1:1 DAR 87:65], 18028 kb/s, 4.14 fps, 4 tbr, 4k tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-07-15T10:27:38.000000Z\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : AVC Coding\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 117 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-07-15T10:27:38.000000Z\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[swscaler @ 0x152fc4016240] deprecated pixel format used, make sure you did set range correctly\n",
      "Output #0, image2, to '/rds/general/user/abs121/home/UROP_2024/segment-anything-2/tracking_results/A1-8_5s/outputs/frame/%07d.jpg':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: mp41isom\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(und): Video: mjpeg, yuvj420p(pc, progressive), 1392x1040 [SAR 1:1 DAR 87:65], q=2-31, 200 kb/s, 4 fps, 4 tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2024-07-15T10:27:38.000000Z\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 mjpeg\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "[out#0/image2 @ 0x55bcd1f77b80] video:12387KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: unknown\n",
      "frame=   27 fps=0.0 q=2.0 Lsize=N/A time=00:00:06.50 bitrate=N/A speed=28.1x    \n",
      "frame loading (JPEG):  48%|████▊     | 13/27 [00:01<00:01, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAM initialised!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame loading (JPEG): 100%|██████████| 27/27 [00:02<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "propagate in video:  19%|█▊        | 5/27 [00:56<04:08, 11.29s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/queueing.py\", line 575, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/route_utils.py\", line 288, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/blocks.py\", line 1931, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/blocks.py\", line 1528, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/utils.py\", line 671, in async_iteration\n",
      "    return await iterator.__anext__()\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/utils.py\", line 664, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2177, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 859, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/utils.py\", line 647, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/gradio/utils.py\", line 809, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2app.py\", line 291, in begin_track\n",
      "    for out_frame_idx, out_obj_ids, out_mask_logits in predictor.propagate_in_video(inference_state):\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 57, in generator_context\n",
      "    response = gen.send(request)\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/sam2_video_predictor.py\", line 643, in propagate_in_video\n",
      "    current_out, pred_masks = self._run_single_frame_inference(\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/sam2_video_predictor.py\", line 786, in _run_single_frame_inference\n",
      "    current_out = self.track_step(\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/sam2_base.py\", line 744, in track_step\n",
      "    pix_feat_with_mem = self._prepare_memory_conditioned_features(\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/sam2_base.py\", line 653, in _prepare_memory_conditioned_features\n",
      "    pix_feat_with_mem = self.memory_attention(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/memory_attention.py\", line 155, in forward\n",
      "    output = layer(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/memory_attention.py\", line 94, in forward\n",
      "    tgt = self._forward_ca(tgt, memory, query_pos, pos, num_k_exclude_rope)\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/memory_attention.py\", line 74, in _forward_ca\n",
      "    tgt2 = self.cross_attn_image(\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/rds/general/user/abs121/home/anaconda3/envs/sam-2-test/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/rds/general/user/abs121/home/UROP_2024/segment-anything-2/sam2/modeling/sam/transformer.py\", line 322, in forward\n",
      "    out = F.scaled_dot_product_attention(q, k, v, dropout_p=dropout_p)\n",
      "torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 8.92 GiB. GPU 0 has a total capacity of 23.64 GiB of which 244.50 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 15.28 GiB is allocated by PyTorch, and 7.93 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "%run sam2app.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sam-2-test]",
   "language": "python",
   "name": "conda-env-sam-2-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
